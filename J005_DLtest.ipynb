{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J005_DLtest.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshbhabhera/Deep-Learning/blob/master/J005_DLtest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d6810SHiyQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvp5YVCci8sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW3xH61ki_B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNg0iUeSjKJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLgKfBuZjVMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmL1NKXQjYNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWUtqt_mjaH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOkk7xrOjcvI",
        "colab_type": "code",
        "outputId": "8d4ca37b-d53b-49e2-9133-71284a0460c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.5544 - acc: 0.7975 - val_loss: 0.4330 - val_acc: 0.8414\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.3769 - acc: 0.8610 - val_loss: 0.3882 - val_acc: 0.8572\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3366 - acc: 0.8765 - val_loss: 0.3922 - val_acc: 0.8554\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3090 - acc: 0.8857 - val_loss: 0.3492 - val_acc: 0.8754\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.2899 - acc: 0.8927 - val_loss: 0.3516 - val_acc: 0.8766\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.2764 - acc: 0.8981 - val_loss: 0.3442 - val_acc: 0.8837\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.2640 - acc: 0.9019 - val_loss: 0.3403 - val_acc: 0.8790\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.2515 - acc: 0.9053 - val_loss: 0.3714 - val_acc: 0.8751\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.2440 - acc: 0.9087 - val_loss: 0.3509 - val_acc: 0.8849\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.2335 - acc: 0.9134 - val_loss: 0.3637 - val_acc: 0.8835\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.2256 - acc: 0.9150 - val_loss: 0.3724 - val_acc: 0.8878\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.2201 - acc: 0.9192 - val_loss: 0.3808 - val_acc: 0.8854\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.2136 - acc: 0.9206 - val_loss: 0.4002 - val_acc: 0.8744\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.2071 - acc: 0.9220 - val_loss: 0.4048 - val_acc: 0.8888\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.2010 - acc: 0.9253 - val_loss: 0.3918 - val_acc: 0.8895\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.1973 - acc: 0.9260 - val_loss: 0.3792 - val_acc: 0.8913\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.1917 - acc: 0.9288 - val_loss: 0.4082 - val_acc: 0.8892\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.1860 - acc: 0.9310 - val_loss: 0.4496 - val_acc: 0.8869\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1884 - acc: 0.9305 - val_loss: 0.4157 - val_acc: 0.8894\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.1807 - acc: 0.9334 - val_loss: 0.4020 - val_acc: 0.8925\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.1797 - acc: 0.9343 - val_loss: 0.4371 - val_acc: 0.8847\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.1725 - acc: 0.9350 - val_loss: 0.4344 - val_acc: 0.8881\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1718 - acc: 0.9363 - val_loss: 0.4518 - val_acc: 0.8931\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1689 - acc: 0.9373 - val_loss: 0.4251 - val_acc: 0.8955\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.1658 - acc: 0.9384 - val_loss: 0.4615 - val_acc: 0.8910\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1635 - acc: 0.9401 - val_loss: 0.4585 - val_acc: 0.8865\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1606 - acc: 0.9410 - val_loss: 0.5078 - val_acc: 0.8869\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1596 - acc: 0.9416 - val_loss: 0.5437 - val_acc: 0.8825\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1579 - acc: 0.9427 - val_loss: 0.4970 - val_acc: 0.8892\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1600 - acc: 0.9437 - val_loss: 0.5192 - val_acc: 0.8919\n",
            "Test loss: 0.5191870986670256\n",
            "Test accuracy: 0.8919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H6W9CKjje_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ417fQGjlq0",
        "colab_type": "code",
        "outputId": "ce1e9fc7-e788-4cf5-d513-29ffcea01ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.1871 - acc: 0.9294 - val_loss: 0.3331 - val_acc: 0.8932\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.1777 - acc: 0.9327 - val_loss: 0.3274 - val_acc: 0.8946\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.1744 - acc: 0.9336 - val_loss: 0.3277 - val_acc: 0.8957\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.1717 - acc: 0.9345 - val_loss: 0.3264 - val_acc: 0.8973\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.1696 - acc: 0.9361 - val_loss: 0.3280 - val_acc: 0.8955\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.1681 - acc: 0.9357 - val_loss: 0.3278 - val_acc: 0.8959\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.1667 - acc: 0.9366 - val_loss: 0.3260 - val_acc: 0.8976\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.1655 - acc: 0.9375 - val_loss: 0.3301 - val_acc: 0.8976\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.1639 - acc: 0.9374 - val_loss: 0.3308 - val_acc: 0.8959\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.1633 - acc: 0.9373 - val_loss: 0.3255 - val_acc: 0.8997\n",
            "Test loss: 0.32551767549812793\n",
            "Test accuracy: 0.8997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gloJZvzjpin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy-HiNIskOFJ",
        "colab_type": "code",
        "outputId": "587c391b-962e-4ef2-a5af-2b0768d756b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.2232 - acc: 0.9171 - val_loss: 0.3798 - val_acc: 0.8837\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.2175 - acc: 0.9194 - val_loss: 0.3921 - val_acc: 0.8876\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.2110 - acc: 0.9231 - val_loss: 0.3983 - val_acc: 0.8900\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.2068 - acc: 0.9246 - val_loss: 0.4130 - val_acc: 0.8832\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.2014 - acc: 0.9258 - val_loss: 0.4562 - val_acc: 0.8804\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.2002 - acc: 0.9261 - val_loss: 0.4049 - val_acc: 0.8880\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.1941 - acc: 0.9277 - val_loss: 0.4272 - val_acc: 0.8878\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.1917 - acc: 0.9287 - val_loss: 0.4967 - val_acc: 0.8575\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.1871 - acc: 0.9315 - val_loss: 0.4925 - val_acc: 0.8850\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.1850 - acc: 0.9315 - val_loss: 0.5094 - val_acc: 0.8664\n",
            "Test loss: 0.5094234839558601\n",
            "Test accuracy: 0.8664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHkwrrtGj2qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ydLvIrKj6e-",
        "colab_type": "code",
        "outputId": "df7e5c09-d9fe-4345-cfd6-e83c139e09b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 1.0954 - acc: 0.8892 - val_loss: 0.4447 - val_acc: 0.8987\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.1134 - acc: 0.9568 - val_loss: 0.4550 - val_acc: 0.8993\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0977 - acc: 0.9627 - val_loss: 0.4655 - val_acc: 0.9007\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0907 - acc: 0.9653 - val_loss: 0.4715 - val_acc: 0.9009\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0852 - acc: 0.9674 - val_loss: 0.4828 - val_acc: 0.9027\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0812 - acc: 0.9692 - val_loss: 0.4893 - val_acc: 0.9000\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0774 - acc: 0.9710 - val_loss: 0.4778 - val_acc: 0.9019\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0745 - acc: 0.9721 - val_loss: 0.4913 - val_acc: 0.9011\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0722 - acc: 0.9733 - val_loss: 0.4960 - val_acc: 0.9014\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0695 - acc: 0.9738 - val_loss: 0.5073 - val_acc: 0.9015\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0678 - acc: 0.9747 - val_loss: 0.5004 - val_acc: 0.9006\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0658 - acc: 0.9755 - val_loss: 0.5089 - val_acc: 0.9022\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0639 - acc: 0.9764 - val_loss: 0.5170 - val_acc: 0.9036\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0621 - acc: 0.9766 - val_loss: 0.5166 - val_acc: 0.9016\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0601 - acc: 0.9780 - val_loss: 0.5277 - val_acc: 0.9006\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0590 - acc: 0.9787 - val_loss: 0.5159 - val_acc: 0.9013\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0574 - acc: 0.9794 - val_loss: 0.5282 - val_acc: 0.9000\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0560 - acc: 0.9798 - val_loss: 0.5236 - val_acc: 0.9010\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0546 - acc: 0.9807 - val_loss: 0.5265 - val_acc: 0.9015\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0529 - acc: 0.9814 - val_loss: 0.5368 - val_acc: 0.9018\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0520 - acc: 0.9813 - val_loss: 0.5305 - val_acc: 0.9022\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0507 - acc: 0.9824 - val_loss: 0.5419 - val_acc: 0.8999\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0494 - acc: 0.9831 - val_loss: 0.5374 - val_acc: 0.8996\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0482 - acc: 0.9838 - val_loss: 0.5530 - val_acc: 0.8983\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0475 - acc: 0.9838 - val_loss: 0.5471 - val_acc: 0.9010\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0462 - acc: 0.9844 - val_loss: 0.5470 - val_acc: 0.9013\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0451 - acc: 0.9849 - val_loss: 0.5612 - val_acc: 0.9004\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0442 - acc: 0.9850 - val_loss: 0.5495 - val_acc: 0.8998\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0431 - acc: 0.9858 - val_loss: 0.5641 - val_acc: 0.8996\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0422 - acc: 0.9860 - val_loss: 0.5591 - val_acc: 0.9008\n",
            "Test loss: 0.5591169762227685\n",
            "Test accuracy: 0.9008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXSnFXfbkXrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnjWXhv_kaCG",
        "colab_type": "code",
        "outputId": "a71b9f08-af7b-4311-8468-fb65a83b4622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.1448 - acc: 0.9439 - val_loss: 0.4420 - val_acc: 0.8981\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1346 - acc: 0.9480 - val_loss: 0.5143 - val_acc: 0.8786\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1286 - acc: 0.9508 - val_loss: 0.4380 - val_acc: 0.8946\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1240 - acc: 0.9522 - val_loss: 0.5067 - val_acc: 0.8915\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1213 - acc: 0.9541 - val_loss: 0.4647 - val_acc: 0.8990\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.1171 - acc: 0.9555 - val_loss: 0.4499 - val_acc: 0.8992\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.1155 - acc: 0.9545 - val_loss: 0.5097 - val_acc: 0.8933\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1116 - acc: 0.9566 - val_loss: 0.4723 - val_acc: 0.8977\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1090 - acc: 0.9576 - val_loss: 0.4927 - val_acc: 0.8959\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.1071 - acc: 0.9587 - val_loss: 0.4959 - val_acc: 0.8962\n",
            "Test loss: 0.49592679820172486\n",
            "Test accuracy: 0.8962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SX_pu4HkbqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXKL1NC5keoM",
        "colab_type": "code",
        "outputId": "57ced439-96f2-4c67-f12a-7d208786a860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.1540 - acc: 0.9440 - val_loss: 0.4584 - val_acc: 0.8926\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.1395 - acc: 0.9486 - val_loss: 0.4675 - val_acc: 0.8972\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.1371 - acc: 0.9486 - val_loss: 0.4361 - val_acc: 0.8925\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.1289 - acc: 0.9518 - val_loss: 0.4412 - val_acc: 0.8956\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.1368 - acc: 0.9501 - val_loss: 0.4194 - val_acc: 0.8957\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.1241 - acc: 0.9530 - val_loss: 0.4556 - val_acc: 0.8882\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1189 - acc: 0.9547 - val_loss: 0.4394 - val_acc: 0.8913\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.1113 - acc: 0.9577 - val_loss: 0.4650 - val_acc: 0.8929\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1106 - acc: 0.9580 - val_loss: 0.4598 - val_acc: 0.8977\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1110 - acc: 0.9582 - val_loss: 0.4656 - val_acc: 0.8970\n",
            "Test loss: 0.4656123359799385\n",
            "Test accuracy: 0.897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_TsWywPkijZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zuUvkHVkmBp",
        "colab_type": "code",
        "outputId": "fb08eda6-6eb0-46be-e6c7-6dd48910e145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0818 - acc: 0.9691 - val_loss: 0.4790 - val_acc: 0.9006\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0674 - acc: 0.9743 - val_loss: 0.4979 - val_acc: 0.8981\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0642 - acc: 0.9745 - val_loss: 0.5092 - val_acc: 0.9036\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0610 - acc: 0.9760 - val_loss: 0.5154 - val_acc: 0.8998\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0586 - acc: 0.9781 - val_loss: 0.5160 - val_acc: 0.9031\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0557 - acc: 0.9789 - val_loss: 0.5174 - val_acc: 0.9016\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0544 - acc: 0.9792 - val_loss: 0.5505 - val_acc: 0.8998\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0515 - acc: 0.9802 - val_loss: 0.5451 - val_acc: 0.9026\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0489 - acc: 0.9816 - val_loss: 0.5463 - val_acc: 0.9029\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0469 - acc: 0.9822 - val_loss: 0.5593 - val_acc: 0.9023\n",
            "Test loss: 0.5593132752241101\n",
            "Test accuracy: 0.9023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaXvYo9skrmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06Ujuegakvtk",
        "colab_type": "code",
        "outputId": "33acd731-bcaf-4d62-9108-870f42f7bf89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1243 - acc: 0.9560 - val_loss: 0.5815 - val_acc: 0.8881\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.1241 - acc: 0.9554 - val_loss: 0.4954 - val_acc: 0.8867\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.1193 - acc: 0.9573 - val_loss: 0.5131 - val_acc: 0.8909\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.1065 - acc: 0.9614 - val_loss: 0.5370 - val_acc: 0.8939\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0975 - acc: 0.9624 - val_loss: 0.5336 - val_acc: 0.8870\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.1008 - acc: 0.9618 - val_loss: 0.4873 - val_acc: 0.8961\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0945 - acc: 0.9647 - val_loss: 0.5167 - val_acc: 0.8900\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.1021 - acc: 0.9624 - val_loss: 0.5099 - val_acc: 0.8940\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.1000 - acc: 0.9628 - val_loss: 0.5375 - val_acc: 0.8906\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.1001 - acc: 0.9631 - val_loss: 0.5124 - val_acc: 0.8928\n",
            "Test loss: 0.5124222384929658\n",
            "Test accuracy: 0.8928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32hU2G-kxxD",
        "colab_type": "code",
        "outputId": "0dd66652-0730-43ae-e74a-94788c7f3672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.4464198113840073\n",
            "Test accuracy: 0.892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji97eQahk1Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsoKORhk4LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBnZECTAk6b_",
        "colab_type": "code",
        "outputId": "f69654e4-1002-4b3b-a075-8e4259a3de24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "history=model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0672 - acc: 0.9748 - val_loss: 0.4783 - val_acc: 0.9018\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0534 - acc: 0.9806 - val_loss: 0.4973 - val_acc: 0.9031\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0497 - acc: 0.9811 - val_loss: 0.4983 - val_acc: 0.9029\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0462 - acc: 0.9829 - val_loss: 0.5257 - val_acc: 0.9024\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0435 - acc: 0.9839 - val_loss: 0.5262 - val_acc: 0.9056\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0407 - acc: 0.9852 - val_loss: 0.5342 - val_acc: 0.9065\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0391 - acc: 0.9853 - val_loss: 0.5623 - val_acc: 0.9026\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0371 - acc: 0.9860 - val_loss: 0.5553 - val_acc: 0.9034\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0346 - acc: 0.9872 - val_loss: 0.5731 - val_acc: 0.9027\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0333 - acc: 0.9882 - val_loss: 0.5780 - val_acc: 0.9007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RrYfoQIk8Gx",
        "colab_type": "code",
        "outputId": "137fa4e7-e689-4c04-e63b-e7ad7c7a5b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.5780422768231946\n",
            "Test accuracy: 0.9007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cx-oQ4Vk-ce",
        "colab_type": "code",
        "outputId": "e00d6f45-f186-482d-d8cb-46b7396aaed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj58xWQ3lAI3",
        "colab_type": "code",
        "outputId": "addbf9bd-7971-42b7-d2ff-427f41b5d952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch'  )\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nckCYmVkmB4SZmWVyQJiZWab/D4ySaZguehgzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5gcdZ3v8fe3e2YyM8kkIZkJuWeG\nEC5ZbsERFVy5RQygsOeIQlZWRTCHfRbBZfUY9/jgiroLuutZFvIcjRhWvJCjIGvcA0bwtrqskkBC\nIAmBmAQzucBkyHUyt+7+nj+qZvqSnmQmmZqemfq8nqefrvpVdfd3+knqU/Wrql+buyMiIvGVKHUB\nIiJSWgoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBSB+YWb2ZuZmV9WHdj5rZb0/0fUQGi4JA\nRhwz22ZmnWZWW9C+JtwI15emMpGhSUEgI9VWYGH3jJmdDVSXrhyRoUtBICPVd4AP58x/BHg4dwUz\nG2dmD5tZs5m9ZmafM7NEuCxpZv9oZnvMbAtwdZHXfsvMdpnZDjP7kpkl+1ukmU01sxVm9qaZbTaz\nj+csu8DMVpvZATN73cy+FrZXmtl3zazFzPaZ2SozO7m/ny3STUEgI9XvgLFmdma4gb4B+G7BOvcD\n44BTgIsJguOmcNnHgfcC84BG4LqC1/4rkAJODde5ArjlOOpcDjQBU8PP+Hszuyxcdh9wn7uPBWYD\nPwjbPxLWPQOYCNwKtB3HZ4sACgIZ2bqPCt4NbAR2dC/ICYfPuvtBd98G/BPwF+EqHwT+2d23u/ub\nwD/kvPZk4Crgk+7e6u5vAP87fL8+M7MZwEXAZ9y93d3XAg+SPZLpAk41s1p3P+Tuv8tpnwic6u5p\nd3/O3Q/057NFcikIZCT7DvDnwEcp6BYCaoFy4LWctteAaeH0VGB7wbJus8LX7gq7ZvYB3wAm9bO+\nqcCb7n6wlxpuBk4DXg67f96b83etBJab2U4z+4qZlffzs0V6KAhkxHL31whOGl8F/Khg8R6CPetZ\nOW0zyR417CLoesld1m070AHUuvv48DHW3f+knyXuBCaYWU2xGtz9VXdfSBAw9wKPmtlod+9y9y+4\n+1zgQoIurA8jcpwUBDLS3Qxc5u6tuY3uniboc/+ymdWY2SzgTrLnEX4A3G5m083sJGBxzmt3AT8D\n/snMxppZwsxmm9nF/SnM3bcDzwD/EJ4APies97sAZnajmdW5ewbYF74sY2aXmtnZYffWAYJAy/Tn\ns0VyKQhkRHP3P7j76l4WfwJoBbYAvwW+DywLl32ToPvlBeB5jjyi+DBQAWwA9gKPAlOOo8SFQD3B\n0cHjwOfd/elw2QJgvZkdIjhxfIO7twGTw887QHDu49cE3UUix8X0wzQiIvGmIwIRkZhTEIiIxJyC\nQEQk5iINAjNbYGabwlvnF/eyzgfNbIOZrTez70dZj4iIHCmyk8XhpW2vENzV2QSsAha6+4acdeYQ\nXKZ3mbvvNbNJ4V2avaqtrfX6+vpIahYRGamee+65Pe5eV2xZlGOiXwBsdvctAGa2HLiW4HK7bh8H\nlrj7XoBjhQBAfX09q1f3djWgiIgUY2av9bYsyq6haeTfot9E9tb5bqcBp5nZf5rZ78xsQbE3MrNF\n4SiMq5ubmyMqV0Qknkp9srgMmANcQnBjzTfNbHzhSu6+1N0b3b2xrq7okY2IiBynKINgB/ljtUwn\nZ/THUBOwIhw7ZSvBOYU5EdYkIiIFojxHsAqYY2YNBAFwA8FIkLn+jeBI4KHwZwVPI7jdv1+6urpo\namqivb39BEsePiorK5k+fTrl5Rp0UkROTGRB4O4pM7uNYLyWJLDM3deb2d3AandfES67wsw2AGng\n0+7e0t/Pampqoqamhvr6esxsIP+MIcndaWlpoampiYaGhlKXIyLDXJRHBLj7E8ATBW135Uw7wYiP\nd57I57S3t8cmBADMjIkTJ6IT5yIyEEp9snjAxCUEusXt7xWR6ER6RCAiIn2Q6oCOQ9BxADoPQcfB\n4vOnXQHT3jLgH68gGAAtLS1cfvnlAOzevZtkMkn3Za7PPvssFRUVx3yPm266icWLF3P66adHWquI\nDJDeNt6dB3M25AfDZQcK5g9mH52HIN3Zt88cM0lBMFRNnDiRtWvXAvB3f/d3jBkzhk996lN567g7\n7k4iUbw37qGHHoq8ThHpA3c4uAt2rYPdL8LuddDafPwb7/LRMKoGRo0JnivGwPhZ+fOjamDU2IK2\ngvmKMdDL9uNEKQgitHnzZq655hrmzZvHmjVreOqpp/jCF77A888/T1tbG9dffz133RWcO3/nO9/J\nAw88wFlnnUVtbS233norTz75JNXV1fz4xz9m0qT+/i66iBxTJgNvboHdL4Qb/nXB8+E92XUmnAJj\np8H4mQUb7nBjfbT5ijGQSJbu7+ujERcEX/jJejbsPDCg7zl36lg+/77+/i554OWXX+bhhx+msbER\ngHvuuYcJEyaQSqW49NJLue6665g7d27ea/bv38/FF1/MPffcw5133smyZctYvLjo4K0i0lepDnhj\nY3Zjv3sd7H4JusKfs06Uw6Qz4LQFMOUcmHw2nHwWVI4tbd2DYMQFwVAze/bsnhAAeOSRR/jWt75F\nKpVi586dbNiw4YggqKqq4sorrwTgLW95C7/5zW8GtWaRYa/9QLZbZ/eLwYa/eSNkUsHyijHBhn7e\nh2DyOcGGv+5MKDv2+byRaMQFwfHuuUdl9OjRPdOvvvoq9913H88++yzjx4/nxhtvLHo3dO7J5WQy\nSSqVGpRaJeY6DsEffgGv/BT2vApVJ0H1BKiaANUnhc8Tc9rC5/LK0tZ98PVwL/+F7N7+3q3Z5aPr\ngo39nPnhRv9cOKkhsv724WjEBcFQduDAAWpqahg7diy7du1i5cqVLFhQdMBVkcGxvwk2PRls/Lf+\nR3ACtHJcsME8tDvoSjncku0+Kaa8OhsW1RPzQ6LYc/WEoC+9v/fCZDLBBj63a2fXOmjNGb3+pPqg\n9nkfgsnnBnv6Y07u/2fFjIJgEJ1//vnMnTuXM844g1mzZnHRRReVuiSJm0wGdq2BTT8NAuD1F4P2\nCafABYuC/vGZb4dkwRhWqQ44/Ca0vZn/fLgF2vbmt+1vCuf3Ar388FWiLDjiyAuJIkHSvi/btbP7\nxeDSzO7X150Bp87P9udPPjsIMem3yH6hLCqNjY1e+MM0Gzdu5MwzzyxRRaUT179b+qnzMGz9dXbP\n/9DrYAmY8XY4fQGcdiXUzhn4veZMGtr3FwmQloK2vfnLCi/LLK8OTtpOOSe/P7/UXVLDjJk95+6N\nxZbpiEBkJDq4O9job/opbPkVpNqgogZOvRxOvxJOfTeMnhhtDYlktiuor9yhszUbEhWjg6OVYXAJ\n5nCmIBAZCdyDrpNXwi6fnc8H7eNmwvkfDvb8Z71z6F8VYxZejz8muG5fBoWCQGS4SnXA1t/AK08G\ne/4HmgALhiC47HNw+lUwaa5OlMoxKQhEhpPWPfDKymDj/4dfBkMdlFfDKZfCJZ+BOe+BmpNLXaUM\nMwoCkaHMHZpfzp7o3f4s4FAzBc7+QLDX3/CnUF5V6kplGFMQiAw16S547T+D7p5XnoS924L2KefC\nxZ8J+vunnKcuHxkwCoIBMBDDUAMsW7aMq666ismTJ0dWqwwBmXRwRUxrc/ZxuCV4btkMm38BHfsh\nOQpOuRguvD24vn/ctFJXLiOUgmAA9GUY6r5YtmwZ559/voJguHEPrpdv3ROMWtmzgS+c3pPd6Be7\n0coSQZfP3PcF1/bPvjS4fFIkYgqCiH37299myZIldHZ2cuGFF/LAAw+QyWS46aabWLt2Le7OokWL\nOPnkk1m7di3XX389VVVV/TqSkAh0Hs7ZqPeyQc9dlukq/j6V44KxbkbXQe2pMOsdwXR1LYyuzS4b\nXRfcaavxb6QERl4QPLk4uJ56IE0+G668p98ve+mll3j88cd55plnKCsrY9GiRSxfvpzZs2ezZ88e\nXnwxqHPfvn2MHz+e+++/nwceeIDzzjtvYOsfirpPgv7hF9C2D3DwTNDumYJ5P8by3Hn6sW7Oe2dS\n2e6awy3B1TjFlFXBmHDDXTMluNM1b4OeM109cehfty/CSAyCIeTpp59m1apVPcNQt7W1MWPGDN7z\nnvewadMmbr/9dq6++mquuOKKElc6SLraguveX10Jr/wM9v8xu8wSgAXPZkeZ78+6dozlifx1qiYE\nd7HmbdALntVVIyPQyAuC49hzj4q787GPfYwvfvGLRyxbt24dTz75JEuWLOGxxx5j6dKlJahwEOzb\nnt3wb/2PYKiD8mo45RL40zthzhU6CSpSYiMvCIaQ+fPnc91113HHHXdQW1tLS0sLra2tVFVVUVlZ\nyQc+8AHmzJnDLbfcAkBNTQ0HDx4scdUnKJ2CpmeDm55e/Rm8sSFoP6k+GOrgtCuCoQ40YJjIkKEg\niNDZZ5/N5z//eebPn08mk6G8vJyvf/3rJJNJbr75ZtwdM+Pee+8F4KabbuKWW24ZfieLW1tg89PB\nnv/mnwdDByfKYOY74IovBXe7RjG6pYgMCA1DPYyV7O92h9dfyu71N60KTr6Orgu6euZcEVz6qLHh\nRYYMDUMtJ66zFbb8Otjrf/UpOLAjaJ9yHrzr08Fe/9R5uvxRZBiKNAjMbAFwH5AEHnT3ewqWfxT4\nKhBuVXjA3R+Msibphze3Bnv8r6yEbb+FdEfwo9+zL4VLPgtz3g01uvlNZLiLLAjMLAksAd4NNAGr\nzGyFu28oWPX/uvttJ/p53f3tcRFJl166C/74X9kunz2vBO0TT4W33hKc6J15oa6NFxlhojwiuADY\n7O5bAMxsOXAtUBgEJ6yyspKWlhYmTpwYizBwd1paWqisHIArbw69EXT1vLoyGNa44wAkyqH+ndD4\nsaC/f+LsE/8cERmyogyCacD2nPkm4G1F1nu/mb0LeAX4a3ffXmSdo5o+fTpNTU00NzcfX6WDKZMO\nHnljzXjObEF7z5PnrVvpbUxPbYE3ngIP3zPvOZMzXzCdSQd30u5aCzueD95zzGSYey2c9p7gGv9R\nNRF+CSIylJT6ZPFPgEfcvcPM/gfwbeCywpXMbBGwCGDmzCN/vq68vJyGhoaISz0OrS2waw3sWAM7\nw8fBnYNchAW/92rJnOdE8DzhFLj0b4O9/inn6vJOkZiKMgh2ADNy5qeTPSkMgLu35Mw+CHyl2Bu5\n+1JgKQSXjw5smQOkbS/seiG7wd+5BvblDKEwcU7Q3TJ1HkxoCK6zt0R245w73b2h7m0Dnrdusfmc\ndm3cReQYogyCVcAcM2sgCIAbgD/PXcHMprj7rnD2GmBjhPUMnPYDsHtd/kb/zS3Z5SfVB78b+9Zb\ngg3/lHN1Tb2IDFmRBYG7p8zsNmAlweWjy9x9vZndDax29xXA7WZ2DZAC3gQ+GlU9x62zNRjNNHej\nv+dVevrsx82AqefBvBvDjf55UD2hpCWLiPTHiLizeMB0tQd3zOZu9JtfDocuJhh2eOq87GPKecGQ\nxCIiQ5zuLC4m1RkMiLZzDex8Pnh+Y2NwNQ0EPxwydR6c+b7sRn/slNLWLCISgfgEwd5twVj43Xv6\nr78E6c5gWeX4YGN/4e3Zvf1x03WiVURiIT5BsP7f4OnPw6ixwcnbt92a3eifVK+NvojEVnyC4NyF\ncMZ7g2vnNTCaiEiP+ARBzcnBQ0RE8mjXWEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoC\nEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTm\nFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZiLNAjMbIGZbTKzzWa2+Cjrvd/M3Mwao6xH\nRESOFFkQmFkSWAJcCcwFFprZ3CLr1QB3AL+PqhYREeldlEcEFwCb3X2Lu3cCy4Fri6z3ReBeoD3C\nWkREpBdRBsE0YHvOfFPY1sPMzgdmuPv/O9obmdkiM1ttZqubm5sHvlIRkRgr2cliM0sAXwP+5ljr\nuvtSd29098a6urroixMRiZEog2AHMCNnfnrY1q0GOAv4lZltA94OrNAJYxGRwRVlEKwC5phZg5lV\nADcAK7oXuvt+d69193p3rwd+B1zj7qsjrElERApEFgTungJuA1YCG4EfuPt6M7vbzK6J6nNFRKR/\nyqJ8c3d/AniioO2uXta9JMpaRESkON1ZLCIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWB\niEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJz\nCgIRkZhTEIiIxJyCQEQk5voUBGY228xGhdOXmNntZjY+2tJERGQw9PWI4DEgbWanAkuBGcD3I6tK\nREQGTV+DIOPuKeC/Afe7+6eBKdGVJSIig6WvQdBlZguBjwD/HraVR1OSiIgMpr4GwU3AO4Avu/tW\nM2sAvhNdWSIiMljK+rKSu28Abgcws5OAGne/N8rCRERkcPT1qqFfmdlYM5sAPA9808y+Fm1pIiIy\nGPraNTTO3Q8A/x142N3fBsw/1ovMbIGZbTKzzWa2uMjyW83sRTNba2a/NbO5/StfREROVF+DoMzM\npgAfJHuy+KjMLAksAa4E5gILi2zov+/uZ7v7ecBXAB1liIgMsr4Gwd3ASuAP7r7KzE4BXj3Gay4A\nNrv7FnfvBJYD1+auEB5ldBsNeB/rERGRAdLXk8U/BH6YM78FeP8xXjYN2J4z3wS8rXAlM/sr4E6g\nAris2BuZ2SJgEcDMmTP7UrKIiPRRX08WTzezx83sjfDxmJlNH4gC3H2Ju88GPgN8rpd1lrp7o7s3\n1tXVDcTHiohIqK9dQw8BK4Cp4eMnYdvR7CAYiqLb9LCtN8uBP+tjPSIiMkD6GgR17v6Qu6fCx78C\nx9o1XwXMMbMGM6sAbiAIkx5mNidn9mqOfd5BREQGWJ/OEQAtZnYj8Eg4vxBoOdoL3D1lZrcRnGRO\nAsvcfb2Z3Q2sdvcVwG1mNh/oAvYSDGEhIiKDyNyPfaGOmc0C7icYZsKBZ4BPuPv2o74wAo2Njb56\n9erB/lgRkWHNzJ5z98Ziy/rUNeTur7n7Ne5e5+6T3P3POPZVQyIiMgycyC+U3TlgVYiISMmcSBDY\ngFUhIiIlcyJBoLuARURGgKNeNWRmBym+wTegKpKKRERkUB01CNy9ZrAKERGR0jiRriERERkBFAQi\nIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwp\nCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGIu0iAwswVmtsnM\nNpvZ4iLL7zSzDWa2zsx+bmazoqxHRESOFFkQmFkSWAJcCcwFFprZ3ILV1gCN7n4O8CjwlajqERGR\n4qI8IrgA2OzuW9y9E1gOXJu7grv/0t0Ph7O/A6ZHWI+IiBQRZRBMA7bnzDeFbb25GXiy2AIzW2Rm\nq81sdXNz8wCWKCIiQ+JksZndCDQCXy223N2XunujuzfW1dUNbnEiIiNcWYTvvQOYkTM/PWzLY2bz\ngf8FXOzuHRHWIyIiRUR5RLAKmGNmDWZWAdwArMhdwczmAd8ArnH3NyKsRUREehFZELh7CrgNWAls\nBH7g7uvN7G4zuyZc7avAGOCHZrbWzFb08nYiIhKRKLuGcPcngCcK2u7KmZ4f5eeLiMixDYmTxSIi\nUjoKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyC\nQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJ\nOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmIg0CM1tgZpvMbLOZLS6y/F1m9ryZpczs\nuihrERGR4iILAjNLAkuAK4G5wEIzm1uw2h+BjwLfj6oOERE5urII3/sCYLO7bwEws+XAtcCG7hXc\nfVu4LBNhHSIichRRdg1NA7bnzDeFbf1mZovMbLWZrW5ubh6Q4kREJDAsTha7+1J3b3T3xrq6ulKX\nIyIyokQZBDuAGTnz08M2EREZQqIMglXAHDNrMLMK4AZgRYSfJyIixyGyIHD3FHAbsBLYCPzA3deb\n2d1mdg2Amb3VzJqADwDfMLP1UdUjIiLFRXnVEO7+BPBEQdtdOdOrCLqMRESkRIbFyWIREYmOgkBE\nJOYUBCIiMacgEBGJudgEwZutnezY10Ym46UuRURkSIn0qqGh5LHnmvjyExsZVZagoXY0DbWjqQ+f\nTwmfJ4yuwMxKXaqIyKCKTRBcesYkqkcl2banla17Wtn0+kGe2vA6qZwjhLGVZT0h0VA7hoa6ICTq\na0czZlRsvioRiZnYbN1OnTSGUyeNyWtLpTM07W1ja0srW5uDgNi6p5VV2/by4xd24jm9SHU1o/KO\nHrofMydWM6osOch/jYjIwIlNEBRTlkxQH+7xX3p6/rL2rjSvtRxm655DbNkTBMW2llae3vg6ew51\n9qyXMJh2UhUNtWOCo4eJ1TTUBdNTx1eRTKirSUSGtlgHwdFUlic5fXINp0+uOWLZ/rauni6m3Mej\nr+3lUEeqZ72KZIJZE6upLziSmDKuiqqKZPAoTyosRKSkFATHYVxVOefOGM+5M8bntbs7zYc62Lbn\nyCOJX7/STGeq+O/vVCQTVJYnqKpIUl1RRmV5kqpwvqo8Gc4n88Kje75n2TGWlydNJ8JFpCgFwQAy\nMybVVDKpppILGibkLUtnnJ372ti6p5XXD7TTnsrQ3pmmrSt8dIaPcL49bNt3uCuvva0zTUcvgXI0\nyYRlwyIMh8qKJJVliby2UT0hkqCyLD9MKrvby48MqMryJJXlCSqSCQWOyDCjIBgkyYQxY0I1MyZU\nn/B7ZTJOeyoIhcOdYWh0ZYOke/5wGC7Z5Zme5Yc7U7R3BfNvtnYG66WCdbrXTx/HPRcJoyckKnOC\np7I8kR8cOSFTUZZgVPioyHmuSCaz04XLk0lGhcHT3VaWjM1tMSIDSkEwDCUSRnVFGdUVZUyM8HO6\n0mFwdKZ7QqM7cNpT6bwjmvauTM9RTE/whKHT3pWhrTPNwfYUzQc78oKrvStDZ3pgfrI6YYShkAyD\n5MhwyVuWFyRBsIzKWac7nEaVJ7PTBesFy7PTFckECZ3zkWFGQSC9Kk8mKE8mGFtZHunnZDJOZzoI\nhM5Uho5U8BxMp3Omw2Xp4ss6w2UdXengueC9OlMZDnem2NdW7HOyrz9R3QGUFxBHDZT89coSCcqS\nRjJhlIWPZDIRPHe3FcwHz8HrcueTCetpK0skSOYtP/J91K0XTwoCKblEwqhMBN1EpdYdSh1dQdB0\nhIHT3pUNi2x7EDo906l0+Lqcdbqy4dTdfqgjRcuhzl7fp5QSRk+gBDsC1rNDUJY0KpK5y/KX9zbd\n/bq890gY5WV9e4/uI7juLsKKnDZ1Bw4MBYFIjvxQivZIqDeZjJPKOKlMhlTGSaeD+XTG6UpnSGey\n86lMJmzPn8++LpNdt2edsD1nPh2ulwo/K5UO5jvTGVLpDF3p/OmudIaudIb2rgwH21N5ban0ka/r\nSmfybtAcKN3dgRXFAiOc7w6TUQVBUp6z7qic6cLwGRUepSXDI6dkzhFUovvZgiOvpGWPxhIJ8p7z\nXmfZ1w8FCgKRISaRMCoSRsUIGxOyO8i6CsLkqNM5XYGdqQwd6cwRbT3T6fxuwNz2g+0pWgrW6Upn\n37O3S7ujZkZPeBSGTDIRBktOwHxy/mm879ypA16HgkBEBkWwkRsaXYCF3D179JJ3Hip47j7aynh4\nZOXZo6lMwXM69+HdR2cZ0g7pTIZ0Jv85Fa6XPtb7ujO+OpqjVAWBiMSemVFRZlSUJWBUqasZfCPr\n2FNERPpNQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzJlHMQBIhMysGXjtOF9e\nC+wZwHKGO30f+fR9ZOm7yDcSvo9Z7l5XbMGwC4ITYWar3b2x1HUMFfo+8un7yNJ3kW+kfx/qGhIR\niTkFgYhIzMUtCJaWuoAhRt9HPn0fWfou8o3o7yNW5whERORIcTsiEBGRAgoCEZGYi00QmNkCM9tk\nZpvNbHGp6ykVM5thZr80sw1mtt7M7ih1TUOBmSXNbI2Z/Xupayk1MxtvZo+a2ctmttHM3lHqmkrF\nzP46/H/ykpk9YmaVpa4pCrEIAjNLAkuAK4G5wEIzm1vaqkomBfyNu88F3g78VYy/i1x3ABtLXcQQ\ncR/wU3c/AziXmH4vZjYNuB1odPezgCRwQ2mrikYsggC4ANjs7lvcvRNYDlxb4ppKwt13ufvz4fRB\ngv/k00pbVWmZ2XTgauDBUtdSamY2DngX8C0Ad+90932lraqkyoAqMysDqoGdJa4nEnEJgmnA9pz5\nJmK+8QMws3pgHvD70lZScv8M/E8gU+pChoAGoBl4KOwqe9DMRpe6qFJw9x3APwJ/BHYB+939Z6Wt\nKhpxCQIpYGZjgMeAT7r7gVLXUypm9l7gDXd/rtS1DBFlwPnA/3H3eUArEMtzamZ2EkHPQQMwFRht\nZjeWtqpoxCUIdgAzcuanh22xZGblBCHwPXf/UanrKbGLgGvMbBtBl+FlZvbd0pZUUk1Ak7t3HyU+\nShAMcTQf2Oruze7eBfwIuLDENUUiLkGwCphjZg1mVkFwwmdFiWsqCTMzgv7fje7+tVLXU2ru/ll3\nn+7u9QT/Ln7h7iNyr68v3H03sN3MTg+bLgc2lLCkUvoj8HYzqw7/31zOCD1xXlbqAgaDu6fM7DZg\nJcGZ/2Xuvr7EZZXKRcBfAC+a2dqw7W/d/YkS1iRDyyeA74U7TVuAm0pcT0m4++/N7FHgeYKr7dYw\nQoea0BATIiIxF5euIRER6YWCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEQKmFnazNbmPAbszlozqzez\nlwbq/UQGQizuIxDppzZ3P8P1kU0AAAFsSURBVK/URYgMFh0RiPSRmW0zs6+Y2Ytm9qyZnRq215vZ\nL8xsnZn93Mxmhu0nm9njZvZC+OgeniBpZt8Mx7n/mZlVleyPEkFBIFJMVUHX0PU5y/a7+9nAAwSj\nlgLcD3zb3c8Bvgf8S9j+L8Cv3f1cgvF6uu9mnwMscfc/AfYB74/47xE5Kt1ZLFLAzA65+5gi7duA\ny9x9Szhw3253n2hme4Ap7t4Vtu9y91ozawamu3tHznvUA0+5+5xw/jNAubt/Kfq/TKQ4HRGI9I/3\nMt0fHTnTaXSuTkpMQSDSP9fnPP9XOP0M2Z8w/BDwm3D658BfQs9vIo8brCJF+kN7IiJHqsoZmRWC\n3+/tvoT0JDNbR7BXvzBs+wTBL3p9muDXvbpH67wDWGpmNxPs+f8lwS9diQwpOkcg0kfhOYJGd99T\n6lpEBpK6hkREYk5HBCIiMacjAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARibn/D3Dm5Nv+U7x8AAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSUOTXwIlE0m",
        "colab_type": "code",
        "outputId": "29c557ab-c19d-4b94-b137-4d01033cb0c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model , to_file= 'model.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPEAAAFgCAIAAADl5AgMAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jbkGq9usydl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}